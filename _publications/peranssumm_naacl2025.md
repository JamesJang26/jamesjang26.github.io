---
title: "YaleNLP @ PerAnsSumm 2025: Multi-Perspective Integration via Mixture-of-Agents for Enhanced Healthcare QA Summarization"
date: 2025-03-29
venue: "CL4Health @ NAACL 2025"
authors: ["Dongsuk Jang", "Alan Li", "Arman Cohan"]
image: "/assets/images/peranssumm_naacl2025.png"
link: ""
description: "Automated summarization of healthcare com- munity question-answering forums is chal- lenging due to diverse perspectives presented across multiple user responses to each ques- tion. The PerAnsSumm Shared Task was therefore proposed to tackle this challenge by identifying perspectives from different an- swers and then generating a comprehensive answer to the question. In this study, we address the PerAnsSumm Shared Task using two complementary paradigms: (i) a training- based approach through QLoRA fine-tuning of LLaMA-3.3-70B-Instruct, and (ii) agen- tic approaches including zero- and few-shot prompting with frontier LLMs (LLaMA-3.3- 70B-Instruct and GPT-4o) and a Mixture-of- Agents (MoA) framework that leverages a di- verse set of LLMs by combining outputs from multi-layer feedback aggregation. For perspec- tive span identification/classification, GPT-4o zero-shot achieves an overall score of 0.57, sub- stantially outperforming the 0.40 score of the LLaMA baseline. With a 2-layer MoA config- uration, we were able to improve LLaMA per- formance up by 28% to 0.51. For perspective- based summarization, GPT-4o zero-shot attains an overall score of 0.42 compared to 0.28 for the best LLaMA zero-shot, and our 2-layer MoA approach boosts LLaMA performance by 32% to 0.37. Furthermore, in few-shot setting, our results show that the sentence-transformer embedding-based exemplar selection provides more gain than manually selected exemplars on LLaMA models, although the few-shot prompt- ing is not always helpful for GPT-4o. The YaleNLP teamâ€™s approach ranked the overall second place in the shared task."
---
