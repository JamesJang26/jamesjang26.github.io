<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> [Project] Tennis Swing Analysis | Dongsuk Jang (장동석, 張東碩) </title> <meta name="author" content="Dongsuk Jang (장동석, 張東碩)"> <meta name="description" content="A system to analyze tennis swings using LSTM and MediaPipe for motion classification."> <meta name="keywords" content="NLP, medical AI, RAG, machine learning, deep learning, academic-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%BE&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jamesjang26.github.io/blog/2024/tennis-swing-analysis/"> <script src="/assets/js/theme.js?v=48c9b5bd7f2e0605e39e579400e22553"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Dongsuk</span> Jang (장동석, 張東碩) </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">[Project] Tennis Swing Analysis</h1> <p class="post-meta"> Created on November 04, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/project"> <i class="fa-solid fa-hashtag fa-sm"></i> Project</a>   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a>   <a href="/blog/tag/computervision"> <i class="fa-solid fa-hashtag fa-sm"></i> ComputerVision</a>   ·   <a href="/blog/category/blog"> <i class="fa-solid fa-tag fa-sm"></i> blog</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="tennis-motion-analysis-system">Tennis Motion Analysis System</h1> <p>This project is a personal hobby endeavor aimed at creating a system that allows users to upload their own tennis videos, which are then analyzed to distinguish between <strong>forehand</strong> and <strong>backhand</strong> motions. The system also provides accuracy feedback by comparing the user’s form to a standard reference and offers suggestions for improvement.</p> <p>To kickstart this project, I used practice videos of one of my favorite tennis players, <strong>Carlos Alcaraz</strong>. Using these videos, I extracted joint positions, manually labeled the motions, and trained a model to classify each movement.</p> <hr> <h2 id="project-overview">Project Overview</h2> <p>Tennis is a sport where recognizing and analyzing complex motions from various angles and speeds is crucial. Identifying and improving specific motions, like forehands and backhands, can offer valuable insights not only for professional players but also for amateurs looking to refine their techniques. The primary goal of this project is to develop a basic system that leverages <strong>LSTM (Long Short-Term Memory)</strong> networks to learn and analyze motion sequences in real-time or post-playback. In future stages, I plan to experiment with different models to enhance accuracy and select the most effective one for motion improvement.</p> <p>For this initial stage, I used <a href="https://github.com/google-ai-edge/mediapipe" rel="external nofollow noopener" target="_blank"><strong>MediaPipe</strong></a>, a pose estimation model, to extract joint positions from the videos. Using these extracted coordinates, I trained an LSTM model to classify motions, focusing on building a foundational system to distinguish tennis strokes.</p> <hr> <h2 id="data-preparation">Data Preparation</h2> <h3 id="1-collecting-videos-from-youtube">1. Collecting Videos from YouTube</h3> <p>First, I collected practice videos of Carlos Alcaraz from <a href="https://www.youtube.com/@slowmotennis/videos" rel="external nofollow noopener" target="_blank">YouTube</a>(Thanks to @Slow-Mo Tennis), slicing into <strong>3 videos, each about 10 minutes long</strong>. Each video includes both <strong>forehand</strong> and <strong>backhand</strong> strokes, making them suitable for training and testing. I used <strong>PyTube</strong> to download these videos directly from YouTube.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pytube</span> <span class="kn">import</span> <span class="n">YouTube</span>

<span class="k">def</span> <span class="nf">download_video</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">save_path</span><span class="p">):</span>
    <span class="n">yt</span> <span class="o">=</span> <span class="nc">YouTube</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">stream</span> <span class="o">=</span> <span class="n">yt</span><span class="p">.</span><span class="n">streams</span><span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="n">progressive</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">file_extension</span><span class="o">=</span><span class="sh">'</span><span class="s">mp4</span><span class="sh">'</span><span class="p">).</span><span class="nf">first</span><span class="p">()</span>
    <span class="n">stream</span><span class="p">.</span><span class="nf">download</span><span class="p">(</span><span class="n">output_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">)</span>

<span class="nf">download_video</span><span class="p">(</span><span class="sh">"</span><span class="s">https://youtu.be/VIDEO_ID</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">./tennis_videos</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="2-extracting-poses-with-mediapipe">2. Extracting Poses with MediaPipe</h3> <p>Next, I used <strong>MediaPipe’s pose estimation model</strong> to process each video, extracting x, y, and z coordinates for key joints in each frame. MediaPipe was selected because of its straightforward setup and ability to quickly capture essential joint information, making it ideal for this project’s initial stages.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">mediapipe</span> <span class="k">as</span> <span class="n">mp</span>

<span class="n">mp_pose</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">solutions</span><span class="p">.</span><span class="n">pose</span>
<span class="n">pose</span> <span class="o">=</span> <span class="n">mp_pose</span><span class="p">.</span><span class="nc">Pose</span><span class="p">(</span><span class="n">static_image_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">min_detection_confidence</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_tracking_confidence</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">VideoCapture</span><span class="p">(</span><span class="sh">'</span><span class="s">./tennis_videos/alcaraz_practice.mp4</span><span class="sh">'</span><span class="p">)</span>
<span class="n">landmarks_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">while</span> <span class="n">cap</span><span class="p">.</span><span class="nf">isOpened</span><span class="p">():</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="p">.</span><span class="nf">read</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">image_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">pose</span><span class="p">.</span><span class="nf">process</span><span class="p">(</span><span class="n">image_rgb</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">results</span><span class="p">.</span><span class="n">pose_landmarks</span><span class="p">:</span>
        <span class="n">frame_landmarks</span> <span class="o">=</span> <span class="p">[{</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">:</span> <span class="n">lm</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">lm</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="sh">"</span><span class="s">z</span><span class="sh">"</span><span class="p">:</span> <span class="n">lm</span><span class="p">.</span><span class="n">z</span><span class="p">}</span> <span class="k">for</span> <span class="n">lm</span> <span class="ow">in</span> <span class="n">results</span><span class="p">.</span><span class="n">pose_landmarks</span><span class="p">.</span><span class="n">landmark</span><span class="p">]</span>
        <span class="n">landmarks_data</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">frame_landmarks</span><span class="p">)</span>
</code></pre></div></div> <h3 id="3-manual-labeling-of-forehand-and-backhand-segments">3. Manual Labeling of Forehand and Backhand Segments</h3> <p>After extracting the joint coordinates, I used the <a href="https://github.com/cvat-ai/cvat" rel="external nofollow noopener" target="_blank"><strong>CVAT annotation tool</strong></a> to manually label each segment as either <strong>forehand</strong> or <strong>backhand</strong>. This labeled data was then organized into a dataset suitable for training the classification model.</p> <p><img src="/assets/img/tennis_cvat1.png" alt="tennis annotation w/ cvat 1"> <img src="/assets/img/tennis_cvat2.png" alt="tennis annotation w/ cvat 2"></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Example of finalized annotation dataset
</span><span class="p">[</span>
    <span class="p">[</span>
        <span class="p">{</span>
            <span class="sh">"</span><span class="s">frame_id</span><span class="sh">"</span><span class="p">:</span> <span class="mi">170</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">Backhand</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">landmarks</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.45166587829589844</span><span class="p">,</span>
                    <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.5477275848388672</span><span class="p">,</span>
                    <span class="sh">"</span><span class="s">z</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.09219522774219513</span><span class="p">,</span>
                    <span class="sh">"</span><span class="s">visibility</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.9998981952667236</span>
                <span class="p">},</span>
                <span class="p">{</span>
                    <span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.44997501373291016</span><span class="p">,</span>
                    <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.5417541265487671</span><span class="p">,</span>
                    <span class="sh">"</span><span class="s">z</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.07722048461437225</span><span class="p">,</span>
                    <span class="sh">"</span><span class="s">visibility</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.9999018907546997</span>
                <span class="p">},</span>
                <span class="c1"># ommited below
</span>            <span class="p">]</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">]</span>
</code></pre></div></div> <hr> <h2 id="model-training">Model Training</h2> <h3 id="data-preprocessing">Data Preprocessing</h3> <p>To prepare the data for training, I standardized and padded each sequence so that they were compatible with the model’s input requirements. Using <code class="language-plaintext highlighter-rouge">StandardScaler</code>, I normalized each joint coordinate, and padded shorter sequences to ensure consistent input length across all sequences.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">json</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="n">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="kn">import</span> <span class="n">joblib</span>

<span class="c1"># Mount Google Drive
</span><span class="n">drive</span><span class="p">.</span><span class="nf">mount</span><span class="p">(</span><span class="sh">'</span><span class="s">/content/drive</span><span class="sh">'</span><span class="p">,</span> <span class="n">force_remount</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Define paths to multiple JSON files for each video and annotation
</span><span class="n">json_paths</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sh">'</span><span class="s">/content/drive/My Drive/tennis/[1]combined_sequences.json</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">/content/drive/My Drive/tennis/[2]combined_sequences.json</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">/content/drive/My Drive/tennis/[3]combined_sequences.json</span><span class="sh">'</span>
<span class="p">]</span>

<span class="c1"># Load and combine data
</span><span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">label_map</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">Forehand</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">Backhand</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>  <span class="c1"># Map labels to numeric values
</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">json_paths</span><span class="p">:</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">sequence_landmarks</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">frame_data</span> <span class="ow">in</span> <span class="n">sequence</span><span class="p">:</span>
                <span class="n">landmarks</span> <span class="o">=</span> <span class="n">frame_data</span><span class="p">[</span><span class="sh">'</span><span class="s">landmarks</span><span class="sh">'</span><span class="p">]</span>
                <span class="c1"># Check if landmarks is a list or dict and flatten accordingly
</span>                <span class="n">landmarks_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">coord</span> <span class="k">for</span> <span class="n">lm</span> <span class="ow">in</span> <span class="n">landmarks</span> <span class="k">for</span> <span class="n">coord</span> <span class="ow">in</span> <span class="p">(</span><span class="n">lm</span><span class="p">[</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">],</span> <span class="n">lm</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">],</span> <span class="n">lm</span><span class="p">[</span><span class="sh">'</span><span class="s">z</span><span class="sh">'</span><span class="p">])]</span> <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">landmarks</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">value</span> <span class="k">for</span> <span class="n">lm</span> <span class="ow">in</span> <span class="n">landmarks</span><span class="p">.</span><span class="nf">values</span><span class="p">()</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="p">(</span><span class="n">lm</span><span class="p">[</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">],</span> <span class="n">lm</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">],</span> <span class="n">lm</span><span class="p">[</span><span class="sh">'</span><span class="s">z</span><span class="sh">'</span><span class="p">])]</span>
                <span class="n">sequence_landmarks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">landmarks_flat</span><span class="p">)</span>
            <span class="n">X</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">sequence_landmarks</span><span class="p">)</span>
            <span class="n">y</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">label_map</span><span class="p">[</span><span class="n">sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">]])</span>

<span class="c1"># Calculate the maximum sequence length for padding
</span><span class="n">max_seq_length</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">X</span><span class="p">)</span>

<span class="c1"># Pad sequences to ensure they are of the same length
</span><span class="n">X_padded</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">seq</span> <span class="o">+</span> <span class="p">[[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nf">len</span><span class="p">(</span><span class="n">seq</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_seq_length</span> <span class="o">-</span> <span class="nf">len</span><span class="p">(</span><span class="n">seq</span><span class="p">))</span> <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">X</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Normalize data with StandardScaler and reshape back
</span><span class="n">scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
<span class="n">X_padded</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_padded</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">X_padded</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">X_padded</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Save scaler for future use
</span><span class="n">scaler_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/tennis/scaler.pkl</span><span class="sh">"</span>
<span class="n">joblib</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="n">scaler_path</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">StandardScaler saved at </span><span class="sh">'</span><span class="si">{</span><span class="n">scaler_path</span><span class="si">}</span><span class="sh">'</span><span class="s">.</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Split data into train and test sets
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X_padded</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Convert to torch tensors
</span><span class="n">X_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_test_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
<span class="n">y_test_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
</code></pre></div></div> <h3 id="model-training-code">Model Training Code</h3> <p>I implemented an LSTM model, structured to analyze sequences of poses and classify each segment as either a forehand or a backhand based on the final frame in each sequence.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>

<span class="k">class</span> <span class="nc">LSTMModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">LSTMModel</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">hidden_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">hidden_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="c1"># Model initialization
</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">X_train_tensor</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">LSTMModel</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Training setup
</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Train the model
</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="nc">TennisDataset</span><span class="p">(</span><span class="n">X_train_tensor</span><span class="p">,</span> <span class="n">y_train_tensor</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="o">=</span> <span class="n">X_batch</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_batch</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s">], Loss: </span><span class="si">{</span><span class="n">running_loss</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Save the trained model
</span><span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/tennis/tennis_model.pth</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <hr> <h2 id="testing-and-analysis-of-results">Testing and Analysis of Results</h2> <h3 id="visualization-of-predictions-on-test-videos">Visualization of Predictions on Test Videos</h3> <p>Using the trained model, I analyzed a test video by inputting each frame’s joint positions and obtaining a forehand or backhand prediction for each segment. The predictions were visually represented on the video, allowing for straightforward evaluation of the model’s performance.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">mediapipe</span> <span class="k">as</span> <span class="n">mp</span>
<span class="kn">import</span> <span class="n">joblib</span>

<span class="c1"># Load the trained model and scaler
</span><span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/drive/My Drive/tennis/tennis_model.pth</span><span class="sh">"</span><span class="p">))</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">joblib</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/drive/My Drive/tennis/scaler.pkl</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Set up MediaPipe and video paths
</span><span class="n">mp_pose</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">solutions</span><span class="p">.</span><span class="n">pose</span>
<span class="n">video_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">/content/drive/My Drive/tennis/[3]pose_output.mp4</span><span class="sh">'</span>
<span class="n">output_video_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/tennis/[3]annotated_video.mp4</span><span class="sh">"</span>

<span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">VideoCapture</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
<span class="n">fourcc</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">VideoWriter_fourcc</span><span class="p">(</span><span class="o">*</span><span class="sh">'</span><span class="s">mp4v</span><span class="sh">'</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">VideoWriter</span><span class="p">(</span><span class="n">output_video_path</span><span class="p">,</span> <span class="n">fourcc</span><span class="p">,</span> <span class="n">cap</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="n">CAP_PROP_FPS</span><span class="p">),</span> 
                      <span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="n">cap</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="n">CAP_PROP_FRAME_WIDTH</span><span class="p">)),</span> <span class="nf">int</span><span class="p">(</span><span class="n">cap</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="n">CAP_PROP_FRAME_HEIGHT</span><span class="p">))))</span>

<span class="c1"># Annotate video with predictions
</span><span class="k">with</span> <span class="n">mp_pose</span><span class="p">.</span><span class="nc">Pose</span><span class="p">(</span><span class="n">static_image_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">min_detection_confidence</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_tracking_confidence</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="k">as</span> <span class="n">pose</span><span class="p">:</span>
    <span class="k">while</span> <span class="n">cap</span><span class="p">.</span><span class="nf">isOpened</span><span class="p">():</span>
        <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="p">.</span><span class="nf">read</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="c1"># Extract landmarks
</span>        <span class="n">image_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">pose</span><span class="p">.</span><span class="nf">process</span><span class="p">(</span><span class="n">image_rgb</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">results</span><span class="p">.</span><span class="n">pose_landmarks</span><span class="p">:</span>
            <span class="n">landmarks_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">coord</span> <span class="k">for</span> <span class="n">lm</span> <span class="ow">in</span> <span class="n">results</span><span class="p">.</span><span class="n">pose_landmarks</span><span class="p">.</span><span class="n">landmark</span> <span class="k">for</span> <span class="n">coord</span> <span class="ow">in</span> <span class="p">(</span><span class="n">lm</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">lm</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="n">lm</span><span class="p">.</span><span class="n">z</span><span class="p">)]</span>
            <span class="n">landmarks_array</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">landmarks_flat</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">landmarks_norm</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">landmarks_array</span><span class="p">)</span>
            <span class="n">landmarks_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">landmarks_norm</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Predict using the model
</span>            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
                <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">landmarks_tensor</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">label</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Forehand</span><span class="sh">"</span> <span class="k">if</span> <span class="n">predicted</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="sh">"</span><span class="s">Backhand</span><span class="sh">"</span>

            <span class="c1"># Annotate frame
</span>            <span class="n">cv2</span><span class="p">.</span><span class="nf">putText</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="n">cv2</span><span class="p">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="sh">"</span><span class="s">Forehand</span><span class="sh">"</span> <span class="nf">else </span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="sh">"</span><span class="s">Forehand</span><span class="sh">"</span> <span class="nf">else </span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
            <span class="n">cv2</span><span class="p">.</span><span class="nf">rectangle</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="n">frame</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="n">frame</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">5</span><span class="p">),</span> <span class="n">color</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

        <span class="n">out</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

<span class="n">cap</span><span class="p">.</span><span class="nf">release</span><span class="p">()</span>
<span class="n">out</span><span class="p">.</span><span class="nf">release</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Annotated video saved to Google Drive:</span><span class="sh">"</span><span class="p">,</span> <span class="n">output_video_path</span><span class="p">)</span>
</code></pre></div></div> <h3 id="observed-issues-and-potential-improvements">Observed Issues and Potential Improvements</h3> <ol> <li> <strong>Labeling Only the Joint Area</strong>: Currently, labels are applied to the entire frame, which reduces clarity. Focusing the labels on just the joint area would improve the visualization.</li> <li> <strong>Smoothing Across Segments</strong>: Rather than predicting each frame independently, applying segment-based smoothing would improve stability by reducing prediction fluctuations across frames.</li> <li> <strong>Limited Data Size</strong>: The small dataset size limits the model’s ability to generalize across different angles and conditions. Expanding the dataset or using data augmentation would likely enhance model performance.</li> </ol> <hr> <h2 id="conclusion">Conclusion</h2> <p>In this project, I used practice videos of Carlos Alcaraz to train an LSTM model that distinguishes between forehand and backhand motions in tennis. By combining MediaPipe’s pose estimation capabilities with the LSTM model, I created a foundational system that analyzes joint coordinates to predict tennis strokes, with visual feedback provided on the test video.</p> <p>However, several limitations were identified: (1) the small dataset size, which limited learning, and (2) the model’s tendency to label every frame across the entire screen, rather than focusing on specific joint areas. Moreover, there’s a need to refine the output by adding smoothing to improve the stability of predictions over sequential frames.</p> <p>Going forward, I plan to improve this system by collecting more data, applying data augmentation techniques, and implementing segment-based smoothing. These enhancements will enable the creation of a more robust and precise tennis motion analysis system.</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Dongsuk Jang (장동석, 張東碩). Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-6R9RGHMNVK"></script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>